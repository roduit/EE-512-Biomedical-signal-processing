{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1777fd9e-dfac-4172-91f3-93b91371299f",
   "metadata": {},
   "source": [
    "# ECG Rhythm Classification\n",
    "\n",
    "The goal of this exercise is to train a neural network model to classify different cardiac rhythm from single-lead ECG signals. The ECG signals we will use are a subset of the large scale 12-lead electrocardiogram database for arrhythmia study (https://physionet.org/content/ecg-arrhythmia/1.0.0/).\n",
    "\n",
    "The subset includes the following cardiac rhythms:\n",
    "\n",
    "* Atrial fibrillation\n",
    "* Atrial flutter\n",
    "* Normal sinus rhythm\n",
    "* Sinus bradycardia\n",
    "* Sinus tachycardia\n",
    "\n",
    "There are 1500 single-lead ECG signals (lead II) for each rhythm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1284b5bf-60e5-420e-8d83-db570c4e17a8",
   "metadata": {},
   "source": [
    "First, we import all required packages, define global constants, and seed the random number generators to obtain reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405cb41e-dd87-4fd3-ad5d-80bddba13a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "import logging\n",
    "import operator\n",
    "import pathlib\n",
    "import warnings\n",
    "\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import torch\n",
    "\n",
    "\n",
    "DATA_FILE = pathlib.Path('../data/ecg_rhythms.npz')\n",
    "LOG_DIRECTORY = pathlib.Path('../logs/ecg_rhythm_classification')\n",
    "\n",
    "\n",
    "# Disable logging for PyTorch Lightning to avoid too long outputs.\n",
    "logging.getLogger('pytorch_lightning').setLevel(logging.ERROR)\n",
    "\n",
    "# Seed random number generators for reproducible results.\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54461a43-66cd-4483-8345-073011b1cd29",
   "metadata": {},
   "source": [
    "Then, we load the ECG signals and the corresponding rhythm annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ffa06-b09d-4d26-b46c-4cf489aa9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with np.load(DATA_FILE) as data:\n",
    "        signals = data['signals']\n",
    "        rhythms = data['rhythms']\n",
    "        fs = data['fs'].item()\n",
    "    return signals, rhythms, fs\n",
    "\n",
    "\n",
    "signals, rhythms, fs = load_data()\n",
    "\n",
    "IPython.display.display(pd.DataFrame(sorted(collections.Counter(rhythms).items()), columns=['rhythm', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5499e8-b40f-4cb5-8406-9401e5366279",
   "metadata": {},
   "source": [
    "Here are a few examples of ECG signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee605f1-d5a1-403f-8eab-d93439f83c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ecg_examples(signals, rhythms, fs):\n",
    "    time = np.arange(signals.shape[-1]) / fs\n",
    "    labels = np.unique(rhythms)\n",
    "    indices = [np.random.choice(np.flatnonzero(rhythms == label)) for label in labels]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(labels), 1, sharex='all', constrained_layout=True)\n",
    "    for ax, index in zip(axes.flat, indices):\n",
    "        label = rhythms[index].replace('_', ' ').capitalize()\n",
    "        plt.sca(ax)\n",
    "        plt.plot(time, signals[index].T, linewidth=1, label=label)\n",
    "        plt.grid()\n",
    "        plt.ylabel('ECG')\n",
    "        plt.legend(loc='upper right')\n",
    "    plt.xlabel('Time [s]')\n",
    "    \n",
    "\n",
    "plot_ecg_examples(signals, rhythms, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f4d033-530b-4d83-883f-17c324ffc0aa",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Visually, what are the differences between the different rhythms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d333ee-2b7a-454d-b81c-f8b3b2703d6d",
   "metadata": {},
   "source": [
    "Then, we split that data into subsets for training, validation, and testing stratified by rhythms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3296c3-6b62-4d76-9d4d-db4903c7689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(rhythms):\n",
    "    n = rhythms.size\n",
    "    splitter = sklearn.model_selection.StratifiedKFold(n_splits=5)\n",
    "    indices = list(map(operator.itemgetter(1), splitter.split(np.zeros((n, 1)), rhythms)))\n",
    "    i_train = np.hstack(indices[:-2])\n",
    "    i_val = indices[-2]\n",
    "    i_test = indices[-1]\n",
    "    \n",
    "    assert np.intersect1d(i_train, i_val).size == 0\n",
    "    assert np.intersect1d(i_train, i_test).size == 0\n",
    "    assert np.intersect1d(i_val, i_test).size == 0\n",
    "    assert np.all(np.sort(np.hstack((i_train, i_val, i_test))) == np.arange(n))\n",
    "    \n",
    "    return i_train, i_val, i_test\n",
    "\n",
    "\n",
    "i_train, i_val, i_test = split_data(rhythms)\n",
    "\n",
    "\n",
    "def build_summary(rhythms, indices):\n",
    "    labels = np.unique(rhythms)\n",
    "    data = []\n",
    "    for subset, i in indices:\n",
    "        y = rhythms[i]\n",
    "        data.append({'subset': subset, 'total_count': y.size})\n",
    "        for label in labels:\n",
    "            data[-1][f'{label}_count'] = np.sum(y == label)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "IPython.display.display(build_summary(rhythms, (('train', i_train), ('val', i_val), ('test', i_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b37d64-1563-4314-8a1f-f4e6eaa6744a",
   "metadata": {},
   "source": [
    "The final preprocessing steps are to scale the ECG signals so that they have approximiately unit variance and to encode the rhythm labels with one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5ff486-a49e-4221-a397-2d3afcf9b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scaling(signals):\n",
    "    sigma = np.std(signals)\n",
    "    return 1.0 / sigma\n",
    "\n",
    "\n",
    "alpha = compute_scaling(signals[i_train])\n",
    "signals *= alpha\n",
    "\n",
    "\n",
    "def encode_rhythms(rhythms):\n",
    "    categories = [np.unique(rhythms)]\n",
    "    encoder = sklearn.preprocessing.OneHotEncoder(categories=categories, sparse_output=False)\n",
    "    return encoder.fit_transform(rhythms[:, None])\n",
    "\n",
    "\n",
    "encoded_rhythms = encode_rhythms(rhythms)\n",
    "\n",
    "\n",
    "def print_encoded_rhythms(rhythms, encoded_rhythms, n=10):\n",
    "    df = pd.DataFrame(encoded_rhythms, columns=np.unique(rhythms))\n",
    "    df.insert(0, 'rhythm', rhythms)\n",
    "    IPython.display.display(df.head(n))\n",
    "    \n",
    "    \n",
    "print_encoded_rhythms(rhythms, encoded_rhythms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b742417-2856-4766-9760-5cc80ab6d79e",
   "metadata": {},
   "source": [
    "We define a class and few utility functions for training and evaluating models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6333ea-a089-40e4-9375-a3a18daf3130",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, model, learning_rate=0.001):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.example_input_array = torch.zeros((1,) + self.model.input_shape)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._run_step(batch, 'train')\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._run_step(batch, 'val')\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._run_step(batch, 'test')\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, y = batch\n",
    "        return self.model(x)\n",
    "    \n",
    "    def _run_step(self, batch, subset):\n",
    "        x, y = batch\n",
    "        logits = self.model(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        acc = (torch.argmax(y, 1) == torch.argmax(logits, 1)).float().mean()\n",
    "        self.log_dict({\n",
    "            f'{subset}_loss': loss,\n",
    "            f'{subset}_acc': acc,\n",
    "        }, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "def build_loader(*tensors, batch_size=100, shuffle=False, n_workers=0):\n",
    "    dataset = torch.utils.data.TensorDataset(*map(torch.Tensor, tensors))\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=n_workers,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_model(name, model, x, y, i_train, i_val, learning_rate=0.001, batch_size=100, n_epochs=10):\n",
    "    train_loader = build_loader(x[i_train], y[i_train], batch_size=batch_size, shuffle=True)\n",
    "    val_loader = build_loader(x[i_val], y[i_val], batch_size=batch_size)\n",
    "    classifier = Classifier(model, learning_rate)\n",
    "    print(pl.utilities.model_summary.ModelSummary(classifier, max_depth=-1))\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        trainer = pl.Trainer(\n",
    "            default_root_dir=LOG_DIRECTORY,\n",
    "            logger=pl.loggers.TensorBoardLogger(LOG_DIRECTORY, name),\n",
    "            enable_model_summary=False,\n",
    "            max_epochs=n_epochs,\n",
    "        )\n",
    "        trainer.fit(classifier, train_loader, val_loader)\n",
    "        \n",
    "    return classifier\n",
    "\n",
    "\n",
    "def evaluate_model(model, x, y, i_train, i_val, i_test, batch_size=100):\n",
    "    loader = build_loader(x, y, batch_size=batch_size)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        trainer = pl.Trainer(\n",
    "            default_root_dir=LOG_DIRECTORY,\n",
    "            logger=False,\n",
    "            enable_progress_bar=False,\n",
    "            enable_model_summary=False,\n",
    "        )\n",
    "        z = trainer.predict(model, loader)\n",
    "    z = np.vstack([u.numpy() for u in z])\n",
    "    \n",
    "    references = np.argmax(y, axis=1)\n",
    "    predictions = np.argmax(z, axis=1)\n",
    "    matrices = {}\n",
    "    for subset, indices in (('train', i_train), ('val', i_val), ('test', i_test)):\n",
    "        matrices[subset] = sklearn.metrics.confusion_matrix(\n",
    "            references[indices], \n",
    "            predictions[indices],\n",
    "        )\n",
    "        \n",
    "    return matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6c915-e148-4eef-83d6-85e4b9c979ce",
   "metadata": {},
   "source": [
    "We start TensorBoard to visualize performance metrics during training.\n",
    "\n",
    "If you prefer to view TensorBoard in a separate window, you can open http://localhost:6006/ in your web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc48069-2c67-4c8f-a955-af041ec575fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ../logs/ecg_rhythm_classification --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c011c385-af73-417f-b133-cdaa78db4942",
   "metadata": {},
   "source": [
    "We define a convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a93e1d-545c-4268-8f15-b8c0e27a5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape, output_shape, kernel_size=5):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(self.input_shape[0], 8, kernel_size, padding='same'),\n",
    "            torch.nn.BatchNorm1d(8),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            \n",
    "            torch.nn.Conv1d(8, 16, kernel_size, padding='same'),\n",
    "            torch.nn.BatchNorm1d(16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            \n",
    "            torch.nn.Conv1d(16, 32, kernel_size, padding='same'),\n",
    "            torch.nn.BatchNorm1d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool1d(2),\n",
    "            \n",
    "            torch.nn.Conv1d(32, 64, kernel_size, padding='same'),\n",
    "            torch.nn.BatchNorm1d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AdaptiveAvgPool1d(1),\n",
    "            \n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(64, self.output_shape[0]),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0acef8-2aab-41c2-999f-42ed608013be",
   "metadata": {},
   "source": [
    "Then, we train and evaluate this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b37de-053d-4415-9aed-f870c660e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = signals.shape[1:]\n",
    "output_shape = encoded_rhythms.shape[1:]\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "cnn = train_model(\n",
    "    name='cnn',\n",
    "    model=CnnModel(input_shape, output_shape),\n",
    "    x=signals,\n",
    "    y=encoded_rhythms,\n",
    "    i_train=i_train,\n",
    "    i_val=i_val,\n",
    "    learning_rate=0.0001,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    ")\n",
    "\n",
    "cnn_matrices = evaluate_model(\n",
    "    model=cnn,\n",
    "    x=signals,\n",
    "    y=encoded_rhythms,\n",
    "    i_train=i_train,\n",
    "    i_val=i_val,\n",
    "    i_test=i_test,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea162c50-de1e-42e1-8793-c861e39bbe9a",
   "metadata": {},
   "source": [
    "After the evaluation is finished, we can plot the confusion matrices for the training, validatoin, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129e2ef-19bb-42cd-a060-a7454d9b41a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(c, labels=None, title=None):\n",
    "    c = np.asarray(c)\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 4), constrained_layout=True)\n",
    "    image = plt.imshow(c, cmap='Blues', interpolation='nearest')\n",
    "\n",
    "    threshold = (c.min() + c.max()) / 2\n",
    "    for i, j in itertools.product(range(c.shape[0]), repeat=2):\n",
    "        if c[i, j] < threshold:\n",
    "            color = image.cmap(image.cmap.N)\n",
    "        else:\n",
    "            color = image.cmap(0)\n",
    "        text = format(c[i, j], '.2g')\n",
    "        if c.dtype.kind != 'f':\n",
    "            integer_text = format(c[i, j], 'd')\n",
    "            if len(integer_text) < len(text):\n",
    "                text = integer_text\n",
    "        plt.text(j, i, text, color=color, ha='center', va='center')\n",
    "\n",
    "    if labels is not None:\n",
    "        plt.xticks(np.arange(c.shape[-1]), labels, rotation=45, ha='right')\n",
    "        plt.yticks(np.arange(c.shape[-1]), labels)\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('References')\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrices(matrices, labels):\n",
    "    for subset in ('train', 'val', 'test'):\n",
    "        c = matrices[subset]\n",
    "        accuracy = np.trace(c) / c.sum()\n",
    "        title = f'{subset.capitalize()} set (accuracy = {accuracy:.3f})'\n",
    "        plot_confusion_matrix(c, labels=labels, title=title)\n",
    "        \n",
    "        \n",
    "plot_confusion_matrices(cnn_matrices, np.unique(rhythms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7807e813-785b-406e-ba49-f91396e6e1d0",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Comment the metrics shown in TensorBoard and the confusion matrices. Does the model overfit? Are there some rhythms that are difficult to classify?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270737b9-f016-4447-9a55-dc220bec85ac",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Define two custom models to classify cardiac rhythms from ECG signals.\n",
    "\n",
    "You can directly define the layers of the custom models in the following classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f97ad-4101-4fb4-9dab-8e896ebe6e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel1(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        # Implement you own model here.\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(np.prod(self.input_shape), self.output_shape[0]),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    \n",
    "class CustomModel2(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "        # Implement you own model here.\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(np.prod(self.input_shape), self.output_shape[0]),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff56fd-5209-458b-951d-8d5965391a28",
   "metadata": {},
   "source": [
    "You can train and evaluate the first custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8f259-c559-4a3b-8c0c-aa2bb564806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom1 = train_model(\n",
    "    name='custom1',\n",
    "    model=CustomModel1(input_shape, output_shape),\n",
    "    x=signals,\n",
    "    y=encoded_rhythms,\n",
    "    i_train=i_train,\n",
    "    i_val=i_val,\n",
    "    learning_rate=0.0001,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    ")\n",
    "\n",
    "custom1_matrices = evaluate_model(\n",
    "    model=custom1,\n",
    "    x=signals,\n",
    "    y=encoded_rhythms,\n",
    "    i_train=i_train,\n",
    "    i_val=i_val,\n",
    "    i_test=i_test,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "plot_confusion_matrices(custom1_matrices, np.unique(rhythms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93efa086-591c-4d3e-a8d8-2fde9c5cb9c8",
   "metadata": {},
   "source": [
    "And then the second custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7175bfc-2c0d-46ac-b996-6a61ff5c8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom2 = train_model(\n",
    "    name='custom2',\n",
    "    model=CustomModel2(input_shape, output_shape),\n",
    "    x=signals,\n",
    "    y=encoded_rhythms,\n",
    "    i_train=i_train,\n",
    "    i_val=i_val,\n",
    "    learning_rate=0.0001,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    ")\n",
    "\n",
    "custom2_matrices = evaluate_model(\n",
    "    model=custom2,\n",
    "    x=signals,\n",
    "    y=encoded_rhythms,\n",
    "    i_train=i_train,\n",
    "    i_val=i_val,\n",
    "    i_test=i_test,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "plot_confusion_matrices(custom2_matrices, np.unique(rhythms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4bab3-48e3-45f6-b4b4-cf56e884f499",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "How do the two custom models perform? Do they overfit? Do they outpeform the first model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
