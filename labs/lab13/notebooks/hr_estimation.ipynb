{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d91915-254f-419c-8dc6-bbc134e8126b",
   "metadata": {},
   "source": [
    "# Heart Rate Estimation\n",
    "\n",
    "The goal of this exercise is to estimate heart rate from PPG and acceleration signals. We signals from the PPG-DaLiA dataset (https://archive.ics.uci.edu/ml/datasets/PPG-DaLiA). It includes PPG and acceleration signals as well as reference heart rate computed from an ECG signal.\n",
    "\n",
    "These signals were collected during various activities but we focus on two of them: sitting and walking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33e5a5-8290-4e78-ad11-b7d1997edfb9",
   "metadata": {},
   "source": [
    "First, we import all the packages we will need, define some global variables, and seed the random number generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e562b-094a-4ff7-bbd8-ec2a9620f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "\n",
    "import copy\n",
    "import functools\n",
    "import itertools\n",
    "import logging\n",
    "import operator\n",
    "import pathlib\n",
    "import warnings\n",
    "\n",
    "import IPython.display\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "\n",
    "DATA_FILE = pathlib.Path('../data/ppg_dalia.pkl')\n",
    "LOG_DIRECTORY = pathlib.Path('../logs/hr_estimation')\n",
    "\n",
    "\n",
    "# Disable logging for PyTorch Lightning to avoid too long outputs.\n",
    "logging.getLogger('pytorch_lightning').setLevel(logging.ERROR)\n",
    "\n",
    "# Seed random number generators for reproducible results.\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ed791-5ad7-4931-94ba-140557ecb6f9",
   "metadata": {},
   "source": [
    "Then, we load the PPG and acceleration signals as well as the reference heart rate. The signals are already pre-processed with the following steps:\n",
    "\n",
    "* Band-pass filtering between 0.4 and 4.0 Hz (24 - 240 bpm).\n",
    "* Resampling to 25 Hz.\n",
    "\n",
    "We also define the window length and shift length used to compute the reference heart rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483637c9-b649-43c8-99fb-f16e3605f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 25.0  # Sampling frequency of the PPG and acceleration signals in Hertz.\n",
    "WINDOW_LENGTH = 8.0  # Window duration in seconds used to compute the reference heart rate.\n",
    "SHIFT_LENGTH = 2.0  # Shift between successive windows in seconds.\n",
    "\n",
    "WINDOW_SIZE = round(FS * WINDOW_LENGTH)\n",
    "SHIFT_SIZE = round(FS * SHIFT_LENGTH)\n",
    "\n",
    "records = joblib.load(DATA_FILE)\n",
    "subjects = set(record['subject'] for record in records)\n",
    "\n",
    "print(f'Window length: {WINDOW_LENGTH} s (n = {WINDOW_SIZE})')\n",
    "print(f'Shift length: {SHIFT_LENGTH} s (n = {SHIFT_SIZE})')\n",
    "print(f'Number of records: {len(records)}')\n",
    "print(f'Number of subjects: {len(subjects)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fce268-ac7a-4008-b44f-f5082288d3d1",
   "metadata": {},
   "source": [
    "Here are two examples of PPG and acceleration signals. One recorded when the subject is sitting and one recorded when the subject is walking.\n",
    "\n",
    "Each figure includes three plots: the tri-axis acceleration signals, the PPG signal, and a spectrogram of the PPG signal with the reference heart rate on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76cf418-29b1-45be-ac78-04f3a8e81cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signals(record):\n",
    "    signals = record['signals']\n",
    "    hr = record['hr']\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, sharex='all', constrained_layout=True)\n",
    "    plt.suptitle(f'{record[\"subject\"]} ({record[\"activity\"]})')\n",
    "\n",
    "    plt.sca(axes.flat[0])\n",
    "    plt.plot(signals['time'].to_numpy(),\n",
    "             signals[['acc_x', 'acc_y', 'acc_z']].to_numpy(),\n",
    "             linewidth=1)\n",
    "    plt.grid()\n",
    "    plt.ylabel('Acceleration')\n",
    "\n",
    "    plt.sca(axes.flat[1])\n",
    "    plt.plot(signals['time'].to_numpy(), signals['ppg'].to_numpy(),\n",
    "             linewidth=1)\n",
    "    plt.grid()\n",
    "    plt.ylabel('PPG')\n",
    "\n",
    "    plt.sca(axes.flat[2])\n",
    "    plt.specgram(signals['ppg'].to_numpy(), Fs=FS, NFFT=WINDOW_SIZE,\n",
    "                 noverlap=WINDOW_SIZE - SHIFT_SIZE)\n",
    "    plt.plot(hr['time'].to_numpy(), hr['hr'].to_numpy() / 60.0,\n",
    "             color='tab:orange', label='Heart rate')\n",
    "    plt.ylim(0.0, 4.0)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "    \n",
    "plot_signals(records[0])\n",
    "plot_signals(records[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a3545-c20f-401b-8d46-1290017e95cb",
   "metadata": {},
   "source": [
    "By zooming on the PPG signal, it is clear that walking cause a degradation in signal quality.\n",
    "\n",
    "We will try to estimate the heart rate on sliding windows of the PPG and acceleration signals. To make things easier, we use the same window length and shift between windows as the reference heart rate.\n",
    "\n",
    "So the next step is to extract sliding windows from all the records. We also extract the corresponding subject identifier for splitting the windows into subsets for training, validation, and testing.\n",
    "\n",
    "In addition, we also prepare windows that include only the PPG signal (first channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77482c0a-5f50-4fdd-b35e-2a61c67aa9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_windows(record):\n",
    "    x = record['signals'][['ppg', 'acc_x', 'acc_y', 'acc_z']].to_numpy()\n",
    "    n = x.shape[0]\n",
    "\n",
    "    windows = []\n",
    "    for start in range(0, n - WINDOW_SIZE + 1, SHIFT_SIZE):\n",
    "        end = start + WINDOW_SIZE\n",
    "        windows.append(x[start:end].T)\n",
    "    windows = np.stack(windows)\n",
    "    targets = record['hr']['hr'].to_numpy()\n",
    "\n",
    "    return windows, targets\n",
    "\n",
    "\n",
    "def extract_all_windows(records):\n",
    "    windows = []\n",
    "    targets = []\n",
    "    subjects = []\n",
    "    activities = []\n",
    "    for record in records:\n",
    "        x, y = extract_windows(record)\n",
    "        windows.append(x)\n",
    "        targets.append(y)\n",
    "        subjects.extend(itertools.repeat(record['subject'], x.shape[0]))\n",
    "        activities.extend(itertools.repeat(record['activity'], x.shape[0]))\n",
    "\n",
    "    windows = np.concatenate(windows, axis=0)\n",
    "    targets = np.concatenate(targets)[:, None]\n",
    "    subjects = np.array(subjects)\n",
    "    activities = np.array(activities)\n",
    "\n",
    "    return windows, targets, subjects, activities\n",
    "\n",
    "\n",
    "ppg_acc_windows, targets, subjects, activities = extract_all_windows(records)\n",
    "ppg_windows = ppg_acc_windows[:, :1, :]\n",
    "\n",
    "print(f'Shape of PPG and accleration windows: {ppg_acc_windows.shape}')\n",
    "print(f'Shape of PPG windows: {ppg_windows.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afffbc6-2335-4d69-b8ae-f842e171963a",
   "metadata": {},
   "source": [
    "We have 7420 windows with 1 or 4 channels and that each window includes 200 samples (8 seconds at 25 Hz).\n",
    "\n",
    "Next, we split the windows for training, validation, and testing by subjects. The test set includes 9 subjects, the validation set 3 subjects, and the test set 3 subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f3030-25e8-4e7e-8e57-7af0683bfb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subjects(subjects):\n",
    "    val_subjects = ('S10', 'S11', 'S12')\n",
    "    test_subjects = ('S13', 'S14', 'S15')\n",
    "\n",
    "    i_val = np.flatnonzero(np.isin(subjects, val_subjects))\n",
    "    i_test = np.flatnonzero(np.isin(subjects, test_subjects))\n",
    "    i_train = np.setdiff1d(np.arange(subjects.size), np.union1d(i_val, i_test))\n",
    "\n",
    "    assert not (set(subjects[i_train]) & set(subjects[i_val]))\n",
    "    assert not (set(subjects[i_train]) & set(subjects[i_test]))\n",
    "    assert not (set(subjects[i_val]) & set(subjects[i_test]))\n",
    "    assert (set(subjects[i_train]) | set(subjects[i_val]) | set(subjects[i_test])) == set(subjects)\n",
    "\n",
    "    return i_train, i_val, i_test\n",
    "\n",
    "\n",
    "i_train, i_val, i_test = split_subjects(subjects)\n",
    "\n",
    "print(f'Subject used for training   : {pd.unique(subjects[i_train])}')\n",
    "print(f'Subject used for validation : {pd.unique(subjects[i_val])}')\n",
    "print(f'Subject used for testing    : {pd.unique(subjects[i_test])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d70f98-bd15-4bfb-a969-bed562cdf458",
   "metadata": {},
   "source": [
    "To make training more stable, we scale the windows such that they have approximately unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5027fc-6038-4404-805e-4caf21cf6a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scaling(windows):\n",
    "    sigma = np.mean(np.std(windows, axis=-1, keepdims=True), axis=0)\n",
    "    return 1.0 / sigma\n",
    "\n",
    "\n",
    "ppg_acc_alpha = compute_scaling(ppg_acc_windows[i_train])\n",
    "ppg_acc_windows *= ppg_acc_alpha\n",
    "ppg_alpha = compute_scaling(ppg_windows[i_train])\n",
    "ppg_windows *= ppg_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21db81b4-c6a3-4da1-85f4-c02b5501c282",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "The windows are scaled but not centered. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1e9bb-f612-4dc3-ae1b-f37291abef9c",
   "metadata": {},
   "source": [
    "Now we define the convolutional neural network (CNN) we will use to estimate heart rate. It is composed of convolutional layers to extract features and dense layers to estimate heart rate. The convolutional layers can optionally include batch normalization and the dense layers dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0902c5-0226-4a7b-9e08-5d7979ab572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_shape,\n",
    "                 output_shape,\n",
    "                 n_convolutional_layers=1,\n",
    "                 kernel_size=5,\n",
    "                 n_initial_channels=16,\n",
    "                 use_normalization=False,\n",
    "                 n_dense_layers=1,\n",
    "                 n_units=128,\n",
    "                 dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.n_convolutional_layers = n_convolutional_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_initial_channels = n_initial_channels\n",
    "        self.use_normalization = use_normalization\n",
    "        self.n_dense_layers = n_dense_layers\n",
    "        self.n_units = n_units\n",
    "        self.dropout = dropout\n",
    "        self.layers = self._build_layers()\n",
    "\n",
    "    @property\n",
    "    def input_size(self):\n",
    "        return functools.reduce(operator.mul, self.input_shape)\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return functools.reduce(operator.mul, self.output_shape)\n",
    "\n",
    "    def _build_layers(self):\n",
    "        layers = self._build_convolutional_layers()\n",
    "        layers.extend(self._build_dense_layers())\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def _build_convolutional_layers(self):\n",
    "        layers = []\n",
    "\n",
    "        n_output_channels = self.input_shape[0]\n",
    "        for i in range(self.n_convolutional_layers):\n",
    "            n_input_channels = n_output_channels\n",
    "            n_output_channels = self.n_initial_channels * 2 ** i\n",
    "            layers.append(torch.nn.Conv1d(\n",
    "                in_channels=n_input_channels,\n",
    "                out_channels=n_output_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                padding='same',\n",
    "            ))\n",
    "            if self.use_normalization:\n",
    "                layers.append(torch.nn.BatchNorm1d(n_output_channels))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            if i < self.n_convolutional_layers - 1:\n",
    "                layers.append(torch.nn.MaxPool1d(kernel_size=2))\n",
    "            else:\n",
    "                layers.append(torch.nn.AdaptiveAvgPool1d(1))\n",
    "        layers.append(torch.nn.Flatten())\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def _build_dense_layers(self):\n",
    "        sizes = [self.n_initial_channels\n",
    "                 * 2 ** (self.n_convolutional_layers - 1)]\n",
    "        sizes.extend(itertools.repeat(self.n_units, self.n_dense_layers - 1))\n",
    "        sizes.append(self.output_size)\n",
    "\n",
    "        layers = []\n",
    "        for i in range(self.n_dense_layers - 1):\n",
    "            layers.append(torch.nn.Linear(sizes[i], sizes[i + 1]))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            if 0.0 < self.dropout < 1.0:\n",
    "                layers.append(torch.nn.Dropout(self.dropout))\n",
    "        layers.append(torch.nn.Linear(sizes[-2], sizes[-1]))\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b8c9c5-b933-4e72-9cf6-4974cae75a57",
   "metadata": {},
   "source": [
    "We also define a class to specify how the model should be trained and evaluated and a few utility functions. It is also here that we select the mean squared error (MSE) as the loss function to optimize the parameters. We also compute the mean absolute error (MAE) as an additional metric to monitor training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87500f59-f121-43ab-b014-9e5e4cd553dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regressor(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.config = config\n",
    "        self.model = CnnModel(**self.config['model'])\n",
    "        self.example_input_array = torch.zeros((1,) + self.model.input_shape)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), **self.config['optimizer'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._run_step(batch, 'train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._run_step(batch, 'val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._run_step(batch, 'test')\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, y = batch\n",
    "        return self.model(x)\n",
    "\n",
    "    def _run_step(self, batch, subset):\n",
    "        x, y = batch\n",
    "        z = self.model(x)\n",
    "        mse = torch.nn.functional.mse_loss(z, y)\n",
    "        mae = torch.nn.functional.l1_loss(z, y)\n",
    "        self.log_dict({\n",
    "            f'{subset}_mse': mse,\n",
    "            f'{subset}_mae': mae,\n",
    "        }, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return mse\n",
    "\n",
    "    \n",
    "def build_loader(*tensors, batch_size=100, shuffle=False, n_workers=0):\n",
    "    dataset = torch.utils.data.TensorDataset(*map(torch.Tensor, tensors))\n",
    "    return torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=n_workers,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_model(config, windows, targets, i_train, i_val, n_epochs, name):\n",
    "    train_loader = build_loader(windows[i_train], targets[i_train], shuffle=True)\n",
    "    val_loader = build_loader(windows[i_val], targets[i_val])\n",
    "    regressor = Regressor(config)\n",
    "    print(pl.utilities.model_summary.ModelSummary(regressor, max_depth=-1))\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        trainer = pl.Trainer(\n",
    "            default_root_dir=LOG_DIRECTORY,\n",
    "            logger=pl.loggers.TensorBoardLogger(LOG_DIRECTORY, name),\n",
    "            enable_model_summary=False,\n",
    "            max_epochs=n_epochs,\n",
    "        )\n",
    "        trainer.fit(regressor, train_loader, val_loader)\n",
    "    \n",
    "    return regressor\n",
    "\n",
    "\n",
    "def compute_metrics(targets, predictions):\n",
    "    targets = targets.ravel()\n",
    "    predictions = predictions.ravel()\n",
    "    return {\n",
    "        'count': targets.size,\n",
    "        'mse': np.mean((targets - predictions) ** 2),\n",
    "        'mae': np.mean(np.abs(targets - predictions)),\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_model(model, windows, targets, i_train, i_val, i_test):\n",
    "    loader = build_loader(windows, targets)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        trainer = pl.Trainer(\n",
    "            default_root_dir=LOG_DIRECTORY,\n",
    "            logger=False,\n",
    "            enable_progress_bar=False,\n",
    "            enable_model_summary=False,\n",
    "        )\n",
    "        predictions = trainer.predict(model, loader)\n",
    "    predictions = np.vstack([p.numpy() for p in predictions])\n",
    "    \n",
    "    metrics = []\n",
    "    for subset, indices in (('train', i_train), ('val', i_val), ('test', i_test)):\n",
    "        metrics.append({\n",
    "            'subset': subset,\n",
    "            **compute_metrics(targets[indices], predictions[indices]),\n",
    "        })\n",
    "    return pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d458e4-fce3-4cd4-a3ee-db26d29138a8",
   "metadata": {},
   "source": [
    "We also start TensorBoard to monitor training.\n",
    "\n",
    "If you prefer to view TensorBoard in a separate window, you can open http://localhost:6006/ in your web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989360e6-a583-4c99-8af3-6940bc4e4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ../logs/hr_estimation --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a386d900-7dba-49b5-ab03-b45f5bf61786",
   "metadata": {},
   "source": [
    "We are finally to define the first model configuration we will train. It includes the following layers:\n",
    "\n",
    "* Input windows (input_size = 200, input channels = 1 or 4)\n",
    "* Convolutional layer (kernel size = 5, output size = 200, output channels = 16)\n",
    "* ReLU activation\n",
    "* Max pooling (output size = 100, output channels = 16)\n",
    "* Convolutional layer (kernel size = 5, output size = 100, output channels = 32)\n",
    "* ReLU activation\n",
    "* Max pooling (output size = 50, output channels = 32)\n",
    "* Convolutional layer (kernel size = 5, output size = 50, output channels = 64)\n",
    "* ReLU activation\n",
    "* Max pooling (output size = 25, output channels = 64)\n",
    "* Convolutional layer (kernel size = 5, output size = 25, output channels = 128)\n",
    "* ReLU activation\n",
    "* Global averaging pooling (output size = 128)\n",
    "* Dense layer (output size = 128)\n",
    "* ReLU activation\n",
    "* Dense layer (output size = 128)\n",
    "* ReLU activation\n",
    "* Dense layer (output size = 1)\n",
    "\n",
    "We use the same configuration for PPG only and PPG and acceleration windows (only the input shape changes).\n",
    "\n",
    "We also define the number of epochs to use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad282de-eb2d-4cb9-a30a-005eff929b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_cnn_config = {\n",
    "    'model': {\n",
    "        'input_shape': ppg_windows.shape[1:],\n",
    "        'output_shape': targets.shape[1:],\n",
    "        'n_convolutional_layers': 4,\n",
    "        'kernel_size': 5,\n",
    "        'n_initial_channels': 16,\n",
    "        'use_normalization': False,\n",
    "        'n_dense_layers': 3,\n",
    "        'n_units': 128,\n",
    "        'dropout': 0.0,\n",
    "    },\n",
    "    'optimizer': {\n",
    "        'lr': 0.0001,\n",
    "    },\n",
    "}\n",
    "ppg_acc_cnn_config = copy.deepcopy(ppg_cnn_config)\n",
    "ppg_acc_cnn_config['model']['input_shape'] = ppg_acc_windows.shape[1:]\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "print('PPG CNN config')\n",
    "IPython.display.display(ppg_cnn_config)\n",
    "print()\n",
    "print('PPG ACC CNN config')\n",
    "IPython.display.display(ppg_acc_cnn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f41e3-1107-4306-a89a-e98301f4967d",
   "metadata": {},
   "source": [
    "We are ready to train the first two models with these configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44887792-97c3-4ac6-b575-09c10d965e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_cnn = train_model(\n",
    "    config=ppg_cnn_config, \n",
    "    windows=ppg_windows, \n",
    "    targets=targets, \n",
    "    i_train=i_train, \n",
    "    i_val=i_val, \n",
    "    n_epochs=n_epochs, \n",
    "    name='ppg_cnn',\n",
    ")\n",
    "\n",
    "ppg_acc_cnn = train_model(\n",
    "    config=ppg_acc_cnn_config, \n",
    "    windows=ppg_acc_windows, \n",
    "    targets=targets, \n",
    "    i_train=i_train, \n",
    "    i_val=i_val, \n",
    "    n_epochs=n_epochs, \n",
    "    name='ppg_acc_cnn',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84df4db6-4d7b-49ed-ace4-5cdbccbf27a4",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Based on metrics shown in TensorBoard, does using the acceleration signals in addition to the PPG signal help to improve performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b069986b-c826-43b2-949e-24f22d2c1f83",
   "metadata": {},
   "source": [
    "We plot the heart rate predicted by these two models for two records from the validation set: one where the subject is sitting and on where the subject is walking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e35c6b7-3853-4b6c-842a-3cc016c738d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(model, record, alpha):\n",
    "    windows, targets = extract_windows(record)\n",
    "    if alpha.shape[0] == 1:\n",
    "        windows = windows[:, :1, :]\n",
    "    windows *= alpha\n",
    "    loader = build_loader(windows, targets)\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        trainer = pl.Trainer(\n",
    "            default_root_dir=LOG_DIRECTORY,\n",
    "            logger=False,\n",
    "            enable_progress_bar=False,\n",
    "            enable_model_summary=False,\n",
    "        )\n",
    "        predictions = trainer.predict(model, loader)\n",
    "    predictions = np.vstack([p.numpy() for p in predictions])\n",
    "    \n",
    "    return targets.ravel(), predictions.ravel()\n",
    "\n",
    "\n",
    "def plot_results(record, models, limits=(0.0, 600.0)):\n",
    "    predictions = {}\n",
    "    for name, (model, alpha) in models.items():\n",
    "        _, predictions[name] = apply_model(model, record, alpha)\n",
    "    \n",
    "    signals = record['signals']\n",
    "    hr = record['hr']\n",
    "    \n",
    "    limits = np.array(limits)\n",
    "    fig, axes = plt.subplots(2, 1, sharex='all', constrained_layout=True)\n",
    "    plt.suptitle(f'{record[\"subject\"]} ({record[\"activity\"]})')\n",
    "    plt.sca(axes.flat[0])\n",
    "    plt.specgram(signals['ppg'].to_numpy(), Fs=FS, NFFT=WINDOW_SIZE,\n",
    "                 noverlap=WINDOW_SIZE - SHIFT_SIZE)\n",
    "    plt.plot(hr['time'].to_numpy(), hr['hr'].to_numpy() / 60.0,\n",
    "             label='Reference')\n",
    "    for name, prediction in predictions.items():\n",
    "        plt.plot(hr['time'].to_numpy(), prediction / 60.0, label=name)\n",
    "    plt.ylim(limits / 60.0)\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.sca(axes.flat[1])\n",
    "    plt.plot(hr['time'].to_numpy(), hr['hr'].to_numpy(), label='Reference')\n",
    "    for name, prediction in predictions.items():\n",
    "        plt.plot(hr['time'].to_numpy(), prediction, label=name)\n",
    "    plt.ylim(limits)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Heart rate [bpm]')\n",
    "    plt.legend(loc='upper right')\n",
    "    \n",
    "\n",
    "models = {\n",
    "    'PPG CNN': (ppg_cnn, ppg_alpha),\n",
    "    'PPG ACC CNN': (ppg_acc_cnn, ppg_acc_alpha),\n",
    "}\n",
    "\n",
    "plot_results(records[21], models)\n",
    "plot_results(records[22], models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66890b6f-16fa-4242-9ebe-0c95713a6271",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "What can you say about the predictions computed with the two models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e74d5-846c-4a71-b74d-4b7e00308116",
   "metadata": {},
   "source": [
    "Next, we modify the configuration of the model using both PPG and acceleration to add batch normalization after each convolution layer. We do not do the same for the model using only PPG since it does not work at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ee63a-e2a5-44d6-9bd7-ee15cb5fdbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_acc_norm_cnn_config = copy.deepcopy(ppg_acc_cnn_config)\n",
    "ppg_acc_norm_cnn_config['model']['use_normalization'] = True\n",
    "\n",
    "print('PPG ACC norm CNN config')\n",
    "IPython.display.display(ppg_acc_norm_cnn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5494a19-91c9-4dd9-8ac3-7f4dff62c23f",
   "metadata": {},
   "source": [
    "We train a model with this new configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be1b58-863f-46d2-9903-b7d0095cad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_acc_norm_cnn = train_model(\n",
    "    config=ppg_acc_norm_cnn_config, \n",
    "    windows=ppg_acc_windows, \n",
    "    targets=targets, \n",
    "    i_train=i_train, \n",
    "    i_val=i_val, \n",
    "    n_epochs=n_epochs, \n",
    "    name='ppg_acc_norm_cnn',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9333db4a-8df1-4525-a0bd-af14890573bb",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "What is the effect of batch normalization on the training procedure and on the perforance metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3014fce6-73ca-4846-a513-6404a8de53c1",
   "metadata": {},
   "source": [
    "We plot the predicted heart rate with respect to the reference for these new models (and we drop the one that did not work at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd989a8a-4918-4521-afeb-35ed8c61b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'PPG ACC CNN': (ppg_acc_cnn, ppg_acc_alpha),\n",
    "    'PPG ACC norm CNN': (ppg_acc_norm_cnn, ppg_acc_alpha), \n",
    "}\n",
    "\n",
    "plot_results(records[21], models)\n",
    "plot_results(records[22], models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72c4685-a8c6-4201-bd36-6e9b7d8356d1",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Visually, is there a large difference between the CNN models with and without batch normalization on these examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5e2c8-99cd-44fb-99ac-26c172d0eb38",
   "metadata": {},
   "source": [
    "Finally, we try another configuration where we add dropout after each dense layer (except the last one which is the output layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29c593-7876-433e-9da4-e0931d354681",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_acc_norm_dropout_cnn_config = copy.deepcopy(ppg_acc_norm_cnn_config)\n",
    "ppg_acc_norm_dropout_cnn_config['model']['dropout'] = 0.5\n",
    "\n",
    "print('PPG ACC norm dropout CNN config')\n",
    "IPython.display.display(ppg_acc_norm_dropout_cnn_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e272a9-a744-4480-9f3f-6cbc62b0c0a1",
   "metadata": {},
   "source": [
    "And we train a new model with this configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b65adc-da4d-440d-939b-2abbf4d7ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppg_acc_norm_dropout_cnn = train_model(\n",
    "    config=ppg_acc_norm_dropout_cnn_config, \n",
    "    windows=ppg_acc_windows, \n",
    "    targets=targets, \n",
    "    i_train=i_train, \n",
    "    i_val=i_val, \n",
    "    n_epochs=n_epochs, \n",
    "    name='ppg_acc_norm_dropout_cnn',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af346d10-176e-4115-82de-3d7da418a664",
   "metadata": {},
   "source": [
    "**Question 6**\n",
    "\n",
    "Does using dropout help to reduce overfitting compare to the same model without dropout?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff22c207-8ab3-428c-9391-3f98182b6f8a",
   "metadata": {},
   "source": [
    "Again, we plot the predicted heart rate for two records from the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff91416-0151-4c58-9dae-bd18a0050bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'PPG ACC CNN': (ppg_acc_cnn, ppg_acc_alpha),\n",
    "    'PPG ACC norm CNN': (ppg_acc_norm_cnn, ppg_acc_alpha),\n",
    "    'PPG ACC norm dropout': (ppg_acc_norm_dropout_cnn, ppg_acc_alpha),\n",
    "}\n",
    "\n",
    "plot_results(records[21], models)\n",
    "plot_results(records[22], models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c3c88-a844-4424-b678-6a6202b7a1d3",
   "metadata": {},
   "source": [
    "Finally, we compute performance metrics (MSE and MAE) for all models on the subsets for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505ab72b-be26-48b0-8e26-996ef89005a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'PPG CNN': ppg_cnn,\n",
    "    'PPG ACC CNN': ppg_acc_cnn,\n",
    "    'PPG ACC norm CNN': ppg_acc_norm_cnn,\n",
    "    'PPG ACC norm dropout': ppg_acc_norm_dropout_cnn,\n",
    "}\n",
    "\n",
    "metrics = []\n",
    "for name, model in models.items():\n",
    "    if 'ACC' in name:\n",
    "        windows = ppg_acc_windows\n",
    "    else:\n",
    "        windows = ppg_windows\n",
    "    df = evaluate_model(model, windows, targets, i_train, i_val, i_test)\n",
    "    df.insert(0, 'model', name)\n",
    "    metrics.append(df)\n",
    "metrics = pd.concat(metrics, axis=0, ignore_index=True)\n",
    "metrics = metrics.set_index(['model', 'subset'])\n",
    "index = metrics.index.get_level_values(0).unique()\n",
    "columns = pd.MultiIndex.from_product([metrics.columns, metrics.index.get_level_values(1).unique()])\n",
    "metrics = metrics.unstack().reindex(index=index, columns=columns)\n",
    "IPython.display.display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53ca829-2c1e-4d4c-9b50-ea03a7f47b57",
   "metadata": {},
   "source": [
    "**Question 7**\n",
    "\n",
    "What is the best model in terms of MSE and MAE? What can you say about batch normalizaton and dropout?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
