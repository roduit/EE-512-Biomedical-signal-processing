{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d91915-254f-419c-8dc6-bbc134e8126b",
   "metadata": {},
   "source": [
    "# Heart Rate Estimation\n",
    "\n",
    "The goal of this exercise is to estimate the heart rate from PPG and acceleration signals using regression methods. We use data from the PPG-DaLiA dataset (https://archive.ics.uci.edu/ml/datasets/PPG-DaLiA). It includes PPG and acceleration signals as well as the reference heart rate computed from an ECG signal. These signals were collected during various activity but we focus on two of them: sitting and walking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33e5a5-8290-4e78-ad11-b7d1997edfb9",
   "metadata": {},
   "source": [
    "First, we import all the packages we will need, define some global variables, and seed the random number generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e562b-094a-4ff7-bbd8-ec2a9620f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "\n",
    "import copy\n",
    "import itertools\n",
    "import operator\n",
    "import pathlib\n",
    "import warnings\n",
    "import IPython.display\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "DATA_FILE = pathlib.Path('../data/ppg_dalia.pkl')\n",
    "LOG_DIRECTORY = pathlib.Path('../logs/hr_estimation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ed791-5ad7-4931-94ba-140557ecb6f9",
   "metadata": {},
   "source": [
    "Then, we load the PPG and acceleration signals as well as the reference heart rate. The signals are already pre-processed with the following steps:\n",
    "\n",
    "* Band-pass filtering between 0.4 and 4.0 Hz (24 - 240 bpm).\n",
    "* Resampling to 25 Hz.\n",
    "\n",
    "We also define the window length and shift length used to compute the reference heart rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483637c9-b649-43c8-99fb-f16e3605f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 25.0  # Sampling frequency of the PPG and acceleration signals in Hertz.\n",
    "WINDOW_LENGTH = 8.0  # Window duration in seconds used to compute the reference heart rate.\n",
    "SHIFT_LENGTH = 2.0  # Shift between successive windows in seconds.\n",
    "\n",
    "WINDOW_SIZE = round(FS * WINDOW_LENGTH)\n",
    "SHIFT_SIZE = round(FS * SHIFT_LENGTH)\n",
    "\n",
    "records = joblib.load(DATA_FILE)\n",
    "subjects = set(record['subject'] for record in records)\n",
    "\n",
    "print(f'Window length: {WINDOW_LENGTH} s (n = {WINDOW_SIZE})')\n",
    "print(f'Shift length: {SHIFT_LENGTH} s (n = {SHIFT_SIZE})')\n",
    "print(f'Number of records: {len(records)}')\n",
    "print(f'Number of subjects: {len(subjects)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fce268-ac7a-4008-b44f-f5082288d3d1",
   "metadata": {},
   "source": [
    "Here are two examples of PPG and acceleration signals. One recorded when the subject is sitting and one recorded when the subject is walking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76cf418-29b1-45be-ac78-04f3a8e81cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signals(record):\n",
    "    signals = record['signals']\n",
    "    hr = record['hr']\n",
    "\n",
    "    fig, axes = plt.subplots(3, 1, sharex='all', constrained_layout=True)\n",
    "    plt.suptitle(f'{record[\"subject\"]} ({record[\"activity\"]})')\n",
    "\n",
    "    plt.sca(axes.flat[0])\n",
    "    plt.plot(signals['time'].to_numpy(),\n",
    "             signals[['acc_x', 'acc_y', 'acc_z']].to_numpy(),\n",
    "             linewidth=1)\n",
    "    plt.grid()\n",
    "    plt.ylabel('Acceleration')\n",
    "\n",
    "    plt.sca(axes.flat[1])\n",
    "    plt.plot(signals['time'].to_numpy(), signals['ppg'].to_numpy(),\n",
    "             linewidth=1)\n",
    "    plt.grid()\n",
    "    plt.ylabel('PPG')\n",
    "\n",
    "    plt.sca(axes.flat[2])\n",
    "    plt.specgram(signals['ppg'].to_numpy(), Fs=FS, NFFT=WINDOW_SIZE,\n",
    "                 noverlap=WINDOW_SIZE - SHIFT_SIZE)\n",
    "    plt.plot(hr['time'].to_numpy(), hr['hr'].to_numpy() / 60.0,\n",
    "             color='tab:orange')\n",
    "    plt.ylim(0.0, 4.0)\n",
    "    plt.xlabel('Time [s]')\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    \n",
    "    \n",
    "plot_signals(records[0])\n",
    "plot_signals(records[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a3545-c20f-401b-8d46-1290017e95cb",
   "metadata": {},
   "source": [
    "By zooming on the PPG signal, it is clear that walking cause a degradation in signal quality.\n",
    "\n",
    "We will try to estimate the heart rate on sliding windows of the PPG and acceleration signals. To make things easier, we use the same window length and shift between windows as the reference heart rate.\n",
    "\n",
    "So the next step is to extract sliding windows from all the records. We also extract the corresponding subject identifier for splitting the windows into subsets for training, validation, and testing.\n",
    "\n",
    "In addition, we also prepare windows that include only the PPG signal (first channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77482c0a-5f50-4fdd-b35e-2a61c67aa9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_windows(record):\n",
    "    x = record['signals'][['ppg', 'acc_x', 'acc_y', 'acc_z']].to_numpy()\n",
    "    n = x.shape[0]\n",
    "\n",
    "    windows = []\n",
    "    for i, start in enumerate(range(0, n - WINDOW_SIZE + 1, SHIFT_SIZE)):\n",
    "        end = start + WINDOW_SIZE\n",
    "        windows.append(x[start:end].T)\n",
    "    windows = np.stack(windows)\n",
    "    targets = record['hr']['hr'].to_numpy()\n",
    "\n",
    "    return windows, targets\n",
    "\n",
    "\n",
    "def extract_all_windows(records):\n",
    "    windows = []\n",
    "    targets = []\n",
    "    subjects = []\n",
    "    activities = []\n",
    "    for record in records:\n",
    "        x, y = extract_windows(record)\n",
    "        windows.append(x)\n",
    "        targets.append(y)\n",
    "        subjects.extend(itertools.repeat(record['subject'], x.shape[0]))\n",
    "        activities.extend(itertools.repeat(record['activity'], x.shape[0]))\n",
    "\n",
    "    windows = np.concatenate(windows, axis=0)\n",
    "    targets = np.concatenate(targets)[:, None]\n",
    "    subjects = np.array(subjects)\n",
    "    activities = np.array(activities)\n",
    "\n",
    "    return windows, targets, subjects, activities\n",
    "\n",
    "\n",
    "ppg_acc_windows, targets, subjects, activities = extract_all_windows(records)\n",
    "ppg_windows = ppg_acc_windows[:, 0, :]\n",
    "\n",
    "print(f'Shape of PPG and accleration windows: {ppg_acc_windows.shape}')\n",
    "print(f'Shape of PPG windows: {ppg_windows.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afffbc6-2335-4d69-b8ae-f842e171963a",
   "metadata": {},
   "source": [
    "We have 7420 windows with 1 or 4 channels and that each window includes 200 samples (8 seconds at 25 Hz)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745808a1-0eaa-4b98-b04c-9ba65a6f39d3",
   "metadata": {},
   "source": [
    "Next, we split the windows for training, validation, and testing by subjects. The test set includes 9 subjects, the validation set 3 subjects, and the test set 3 subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f3030-25e8-4e7e-8e57-7af0683bfb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subjects(subjects):\n",
    "    val_subjects = ('S10', 'S11', 'S12')\n",
    "    test_subjects = ('S13', 'S14', 'S15')\n",
    "\n",
    "    i_val = np.flatnonzero(np.isin(subjects, val_subjects))\n",
    "    i_test = np.flatnonzero(np.isin(subjects, test_subjects))\n",
    "    i_train = np.setdiff1d(np.arange(subjects.size), np.union1d(i_val, i_test))\n",
    "\n",
    "    assert not (set(subjects[i_train]) & set(subjects[i_val]))\n",
    "    assert not (set(subjects[i_train]) & set(subjects[i_test]))\n",
    "    assert not (set(subjects[i_val]) & set(subjects[i_test]))\n",
    "    assert (set(subjects[i_train]) | set(subjects[i_val]) | set(subjects[i_test])) == set(subjects)\n",
    "\n",
    "    return i_train, i_val, i_test\n",
    "\n",
    "\n",
    "i_train, i_val, i_test = split_subjects(subjects)\n",
    "\n",
    "print(f'Subject used for training   : {pd.unique(subjects[i_train])}')\n",
    "print(f'Subject used for validation : {pd.unique(subjects[i_val])}')\n",
    "print(f'Subject used for testing    : {pd.unique(subjects[i_test])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad2c0ec-9323-4530-bc62-8d14d15875f6",
   "metadata": {},
   "source": [
    "Now we extract features from the windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335ce31-ce50-48ee-81bb-73c35afd0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_norm = np.zeros([ppg_acc_windows.shape[0], ppg_acc_windows.shape[2]])\n",
    "for instance in range(ppg_acc_windows.shape[0]):\n",
    "    ppg_acc = ppg_acc_windows[instance, 1:, :]\n",
    "    acc_norm[instance, :] = np.sqrt(np.sum(np.power(ppg_acc, 2), axis=0)) \n",
    "\n",
    "\n",
    "features = pd.DataFrame({\n",
    "    'acc_mean': np.mean(acc_norm, axis=1),\n",
    "    'acc_std': np.std(acc_norm, axis=1),\n",
    "    'acc_min': np.min(acc_norm, axis=1),\n",
    "    'acc_max': np.max(acc_norm, axis=1), \n",
    "    'acc_p2p': np.max(acc_norm, axis=1) - np.min(acc_norm, axis=1), \n",
    "    'acc_var': np.power(np.std(acc_norm, axis=1), 2),\n",
    "    'acc_median': np.median(acc_norm, axis=1),\n",
    "    'ppg_mean': np.mean(ppg_windows, axis=1),\n",
    "    'ppg_std': np.std(ppg_windows, axis=1),\n",
    "    'ppg_min': np.min(ppg_windows, axis=1),\n",
    "    'ppg_max': np.max(ppg_windows, axis=1), \n",
    "    'ppg_p2p': np.max(ppg_windows, axis=1) - np.min(acc_norm, axis=1), \n",
    "    'ppg_var': np.power(np.std(ppg_windows, axis=1), 2),\n",
    "    'ppg_median': np.median(ppg_windows, axis=1),\n",
    "})\n",
    "\n",
    "\n",
    "def plot_features(f, y):\n",
    "    data = f.copy()\n",
    "    data['label'] = y.ravel()\n",
    "    sns.pairplot(data, plot_kws={'s': 4})\n",
    "\n",
    "\n",
    "plot_features(features.iloc[i_train], targets[i_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d70f98-bd15-4bfb-a969-bed562cdf458",
   "metadata": {},
   "source": [
    "It is also possible to select the most relevant features using various methods. Here, we define implement three fature selection techniques: lasso, univariate, hybrid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817153e-d090-4101-be0f-9837771a1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector:\n",
    "\n",
    "    def __init__(self, method, numbers):\n",
    "        self.method = method.lower()\n",
    "        self.numbers = numbers\n",
    "\n",
    "    def apply(self, features, targets):\n",
    "        features_names = [column for column in features.columns \n",
    "                          if column not in ['reference']]\n",
    "        features_selection = features.copy()\n",
    "        features_selection.insert(0, 'reference', targets)\n",
    "        features_selection = features_selection.dropna(axis=0, how='any', inplace=False)\n",
    "        ranks = self.rank_features(features_selection[features_names],\n",
    "                                   features_selection['reference'],\n",
    "                                   self.method)\n",
    "        del features_selection\n",
    "        return self.select_features(ranks, self.numbers)\n",
    "\n",
    "    @staticmethod\n",
    "    def select_features(ranks, feature_num):\n",
    "        ranks.sort_values(by='ranks', axis=0, ascending=False, inplace=True,\n",
    "                          kind='quicksort', ignore_index=True)\n",
    "        return ranks['feature_names'].iloc[: feature_num].tolist()\n",
    "\n",
    "    @staticmethod\n",
    "    def rank_features(features, reference, method):\n",
    "        def univariate_selection(data, ref):\n",
    "            selector = SelectKBest(f_regression, k=\"all\")\n",
    "            scores = selector.fit(data, ref).scores_\n",
    "            return scores / np.nansum(scores)\n",
    "\n",
    "        def lasso_selection(data, ref):\n",
    "            alphas = np.arange(0.01, 0.3, 0.01)\n",
    "            coefficients = np.empty([len(alphas), data.shape[1]])\n",
    "            for row, alpha in enumerate(alphas):\n",
    "                selector = SelectFromModel(Lasso(alpha=alpha), prefit=False)\n",
    "                coefficients[row, :] = selector.fit(data, ref).estimator_.coef_\n",
    "            coefficients = np.abs(coefficients)\n",
    "            real_ranks = np.nansum(coefficients, axis=0)\n",
    "            return real_ranks / np.nansum(real_ranks)\n",
    "\n",
    "        if method == 'lasso':\n",
    "            ranks = lasso_selection(features, reference)\n",
    "        elif method == 'univariate':\n",
    "            ranks = univariate_selection(features, reference)\n",
    "        elif method == 'hybrid':\n",
    "            rank_lasso = lasso_selection(features, reference)\n",
    "            rank_univariate = univariate_selection(features, reference)\n",
    "            rank_combined = rank_lasso + rank_univariate\n",
    "            ranks = rank_combined / np.nansum(rank_combined)\n",
    "        else:\n",
    "            raise TypeError(\"Feature selection method is not supported\")\n",
    "        return pd.DataFrame({\n",
    "            'feature_names': features.columns,\n",
    "            'ranks': ranks,\n",
    "        })\n",
    "\n",
    "feature_selection_method = 'univariate'\n",
    "feature_selection_numbers = 4\n",
    "features_list = FeatureSelector(feature_selection_method, feature_selection_numbers).apply(features.iloc[i_val], targets[i_val])\n",
    "print(f\"Selected features:{features_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a1e9bb-f612-4dc3-ae1b-f37291abef9c",
   "metadata": {},
   "source": [
    "Now we define the regression models: linear regression, support vector regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0902c5-0226-4a7b-9e08-5d7979ab572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder:\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config['model']\n",
    "\n",
    "    def apply(self):\n",
    "        return eval(f\"self._build_{self.config['name']}()\")\n",
    "\n",
    "    def _build_lregression(self):\n",
    "        return make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LinearRegression())\n",
    "\n",
    "    def _build_svr(self, kernel='rbf', gamma='scale', regularization=1):\n",
    "        if 'kernel' in self.config.keys():\n",
    "            kernel = self.config['kernel']\n",
    "        if 'gamma' in self.config.keys():\n",
    "            gamma = self.config['gamma']\n",
    "        if 'regularization' in self.config.keys():\n",
    "            regularization = self.config['regularization']\n",
    "        return make_pipeline(\n",
    "            StandardScaler(),\n",
    "            SVR(kernel=kernel, gamma=gamma, C=regularization))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8880de1-3ece-4666-b619-cdc4cc796007",
   "metadata": {},
   "source": [
    "Now, we define a class for the training of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c928df3-60e1-407e-8ed4-da00ae68119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config['feature']\n",
    "\n",
    "    def apply(self, model, features, reference, i_train):\n",
    "        features_list = self._get_features_list(list(features.columns))\n",
    "        features_train = features.copy()\n",
    "        features_train.insert(0, 'reference', reference)\n",
    "        features_train = features_train.iloc[i_train].copy()\n",
    "        \n",
    "        features_train = features_train.dropna(axis=0, how='any', inplace=False,\n",
    "                                               subset=features_list + ['reference'])\n",
    "        return model.fit(\n",
    "            features_train[features_list].values, features_train['reference'].values)\n",
    "\n",
    "    def _get_features_list(self, current_features):\n",
    "        if 'all' in self.config['list']:\n",
    "            features_list = [feature for feature in current_features\n",
    "                             if feature not in self.config['exclusion'] + ['reference']]\n",
    "        else:\n",
    "            features_list = [feature for feature in\n",
    "                             self.config['list']\n",
    "                             if feature in current_features and feature not\n",
    "                             in self.config['exclusion'] + ['reference']]\n",
    "        return features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1ec9c-d3c8-42fa-a2d8-085963afd889",
   "metadata": {},
   "source": [
    "We also define a class to apply the trained models on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c82621-498d-42d3-b467-a0959603613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config['feature']\n",
    "\n",
    "    def apply(self, model, features):\n",
    "        features_list = self._get_features_list(list(features.columns))\n",
    "        inx = np.logical_not(\n",
    "            np.sum(np.isnan(features[features_list]), 1).astype(bool))\n",
    "        detections = np.zeros_like(inx, dtype=float)\n",
    "        detections[:] = np.nan\n",
    "        detections[inx] = model.predict(features[features_list].values[inx])\n",
    "        return pd.DataFrame({\n",
    "            'prediction': detections,\n",
    "        })\n",
    "\n",
    "    def _get_features_list(self, current_features):\n",
    "        if 'all' in self.config['list']:\n",
    "            features_list = [feature for feature in current_features\n",
    "                             if feature not in self.config['exclusion'] + ['reference']]\n",
    "        else:\n",
    "            features_list = [feature for feature in\n",
    "                             self.config['list']\n",
    "                             if feature in current_features and feature not\n",
    "                             in self.config['exclusion'] + ['reference']]\n",
    "        return features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28474177-09ba-4c44-ad66-6831d9aa37d8",
   "metadata": {},
   "source": [
    "Inorder to evaluate the results of the models, we define an Evaluator class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f71094b-45a6-41c8-a84d-f0cbc0081fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def apply(self, result, reference, i_train, i_test):\n",
    "        metrics = []\n",
    "        for subset, indices in (('train', i_train), ('test', i_test)):\n",
    "            metrics.append({\n",
    "                'subset': subset,\n",
    "                **self.compute_performance_parameters(result[indices], reference[indices]),\n",
    "            })\n",
    "        return pd.DataFrame(metrics)\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_performance_parameters(result, reference):\n",
    "        error = np.zeros_like(reference)\n",
    "        error[:] = np.nan\n",
    "        inx = reference != 0\n",
    "        error[inx] = 100 * ((reference[inx] - result[inx]) / reference[inx])\n",
    "        error = error[error != np.nan]\n",
    "        return {\n",
    "            'mean': np.mean(error),\n",
    "            'std': np.std(error),\n",
    "            'rmse': np.sqrt(np.mean(np.power(error, 2))),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804af741-7b27-486d-9360-7abd6e00cf04",
   "metadata": {},
   "source": [
    "The final step before training and evaluating the models is to define the configurations of the different models.\n",
    "\n",
    "We will train the models with the following configurations:\n",
    "\n",
    "* Linear without features selection\n",
    "  * Using all the features\n",
    "\n",
    "* Linear regression with features selection\n",
    "  * Using the selected features\n",
    "\n",
    "* SVR with features selection\n",
    "  * Using the selected features\n",
    "  * kernel: rbf\n",
    "  * gamma:scale\n",
    "  * regularization: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a51653f-53f7-4a61-862f-7fca7b51ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_features = []\n",
    "configs = {\n",
    "    'linear_regression_all_features': {\n",
    "        'feature': {\n",
    "            'list': 'all',\n",
    "            'exclusion': exclude_features,\n",
    "            'selection_method': [],\n",
    "            'selection_numbers': np.nan,\n",
    "        },\n",
    "        'model': {\n",
    "            'name': 'lregression',\n",
    "        },\n",
    "    },\n",
    "    'linear_regression_selected_features': {\n",
    "        'feature': {\n",
    "            'list': features_list,\n",
    "            'exclusion': exclude_features,\n",
    "            'selection_method': feature_selection_method,\n",
    "            'selection_numbers': feature_selection_numbers,\n",
    "        },\n",
    "        'model': {\n",
    "            'name': 'lregression',\n",
    "        },\n",
    "    },\n",
    "    'svr_all_features': {\n",
    "        'feature': {\n",
    "            'list': 'all',\n",
    "            'exclusion': exclude_features,\n",
    "            'selection_method': [],\n",
    "            'selection_numbers': np.nan,\n",
    "        },\n",
    "        'model': {\n",
    "            'name': 'svr',\n",
    "            'kernel': 'rbf',\n",
    "            'gamma': 'scale',\n",
    "            'regularization': 1, \n",
    "        },\n",
    "    },\n",
    "    'svr_selected_features': {\n",
    "        'feature': {\n",
    "            'list': features_list,\n",
    "            'exclusion': exclude_features,\n",
    "            'selection_method': feature_selection_method,\n",
    "            'selection_numbers': feature_selection_numbers,\n",
    "        },\n",
    "        'model': {\n",
    "            'name': 'svr',\n",
    "            'kernel': 'rbf',\n",
    "            'gamma': 'scale',\n",
    "            'regularization': 1, \n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e086ca-87cf-4466-b733-5eb188a25bcb",
   "metadata": {},
   "source": [
    "Now, we are ready to train the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096788e7-7ded-41ca-b483-3b78b63e742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for name, config in configs.items():\n",
    "    print(f' * Training {name!r} model')\n",
    "    model = ModelBuilder(config).apply()\n",
    "    models[name] = ModelTrainer(config).apply(model, features, targets, i_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30572de0-96be-4e2e-a6a7-20d177e46186",
   "metadata": {},
   "source": [
    "Here, we evaluate the trained models on the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ce297-2196-441f-868c-7c2238a500a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "for name, config in configs.items():\n",
    "    print(f' * Applying {name!r} model')\n",
    "    output[name] = ModelTester(config).apply(models[name], features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85090017-cca8-4f2a-b920-ba4e405f515a",
   "metadata": {},
   "source": [
    "Now that all models are trained we can evaluate them on the subsets for training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a67f29-75d4-4759-bc31-8e736bba77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for name, config in configs.items():\n",
    "    print(f'Evaluating {name!r} model')\n",
    "    performance = Evaluator().apply(output[name]['prediction'].values, targets[:, 0], i_train, i_test)\n",
    "    performance.insert(0, 'model', name)\n",
    "    metrics.append(performance)\n",
    "print(\"\\n*** Performance report ***\\n\")\n",
    "metrics = pd.concat(metrics, axis=0, ignore_index=True)\n",
    "metrics = metrics.set_index(['model', 'subset'])\n",
    "index = metrics.index.get_level_values(0).unique()\n",
    "columns = pd.MultiIndex.from_product([metrics.columns, metrics.index.get_level_values(1).unique()])\n",
    "metrics = metrics.unstack().reindex(index=index, columns=columns)\n",
    "IPython.display.display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c915fdd1-c080-4d62-8908-b50a17071eab",
   "metadata": {},
   "source": [
    "We can also plot the different metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797133e-f2d1-44da-85d8-13de872af8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(data):\n",
    "    for metric in data.columns.get_level_values(0).unique():\n",
    "        if metric == 'count':\n",
    "            continue\n",
    "        df = data[metric]\n",
    "        plt.figure(constrained_layout=True)\n",
    "        plt.gca().set_axisbelow(True)\n",
    "        df.plot(kind='bar', ylabel=metric, ax=plt.gca())\n",
    "        plt.grid(axis='y')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.gca().xaxis.set_tick_params(rotation=45)\n",
    "\n",
    "    \n",
    "plot_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c51fde-da95-437e-8176-28189fad0b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
